# 통계학 6주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_6th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

6주차는 `2부-데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다


## Statistics_6th_TIL

### 2부. 데이터 분석 준비하기

### 11. 데이터 전처리와 파생변수 생성

<!-- 11. 데이터 전처리와 파생변수 생성에서 11.1 결측값 처리부터 11.4 데이터 표준화와 정규화 스케일링 파트까지 진행해주시면 됩니다. -->

## Study ScheduleStudy Schedule

| 주차  | 공부 범위     | 완료 여부 |
| ----- | ------------- | --------- |
| 1주차 | 1부 p.2~46    | ✅         |
| 2주차 | 1부 p.47~81   | ✅         |
| 3주차 | 2부 p.82~120  | ✅         |
| 4주차 | 2부 p.121~167 | ✅         |
| 5주차 | 2부 p.168~202 | ✅         |
| 6주차 | 2부 p.203~250 | ✅         |
| 7주차 | 2부 p.251~299 | 🍽️         |

> 과제가 많이 남지 않았습니다. 조금만 더 화이팅해주세요!

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리 

## 11.데이터 전처리와 파생변수 생성

```
✅ 학습 목표 :
* 결측값과 이상치를 식별하고 적절한 방법으로 처리할 수 있다.
* 데이터 변환과 가공 기법을 학습하고 활용할 수 있다.
* 모델 성능 향상을 위한 파생 변수를 생성하고 활용할 수 있다.
```

## 11.1. 결측값 처리

🎯**학습 목표: 결측값과 이상치를 식별하고 적절한 방법으로 처리할 수 있다.**

결측값은 통계적 **편향**을 증가시키고 유의미한 인사이트를 얻기 어렵게 하므로 적절한 처리가 필수입니다.

### 1. 결측값 식별

* **일반적 표기**: '.', 'NaN', 'NA' 등으로 표시됩니다.
* **EDA를 통한 확인**: 결측값의 비율 및 특정 변수에의 집중 여부를 파악해야 합니다.
* **특수 값 확인**: 결측값으로 인식되지 않는 **빈 문자열**(`''`) 등이 입력되어 있을 수 있으므로 확인이 필요합니다.

### 2. 결측값 처리 방법

| 방법 | 설명 (특징) | 장점 | 단점 |
| :--- | :--- | :--- | :--- |
| **관측치 제거** | 결측값이 많은 변수 제거 또는 해당 행(관측치) 제거 | 간단하고 빠름. 결측값 비율 **10% 미만**에 주로 사용. | 데이터 손실 발생. 표본의 통계적 대표성 상실 우려. |
| **단순 대체 (Simple Imputation)** | 결측값을 특정 통계량으로 대체 | 간편하고 데이터 손실 없음. | 분산을 축소시켜 **통계적 편향**을 증가시키고 p-value를 부정확하게 만듦. |
| *세부 방법* | 평균(Mean), 중앙값(Median), 최빈값(Mode) 또는 0, 최댓값 등으로 대체. | | |
| **보간법 (Interpolation)** | 이전/이후 시점 값을 고려하여 선형적으로 대체 | 시계열 데이터의 **연속성** 보존에 효과적. | 시계열 특성이 없는 데이터에는 부적합. |
| **다중 대체법 (MI)** | 단순 대체법의 편향 문제를 해결하기 위해 사용. | 오차 편향을 줄이고 **변동성(분산)**을 보존. | 복잡하며 처리 시간이 오래 걸림. |
| *세부 방법* | 스토캐스틱 회귀 대체법, MICE (Chained Equation) 등 사용. | | |

## 11.2. 이상치 처리

🎯**학습 목표: 결측값과 이상치를 식별하고 적절한 방법으로 처리할 수 있다.**

이상치는 모평균 및 총합 추정에 문제를 일으키고 **분산을 과도하게 증가**시켜 분석 정확도를 떨어뜨립니다.

### 1. 이상치 식별 방법

* **시각화 (EDA)**: **박스 플롯(Box Plot)**의 극단치(Whisker 밖의 점)가 가장 일반적인 식별 방법입니다.
* **통계적 기준**:
    * 평균($\mu$)을 기준으로 $\pm 3$ **표준편차($\sigma$)** 범위 밖의 값.
    * 분포가 비대칭인 경우 **중앙값 절대 편차(MAD)**를 사용 (중앙값 사용으로 이상치에 덜 민감).
* **도메인 지식**: 단순히 통계적으로 제거하기보다, 이상치가 **비즈니스적으로 중요한 의미**를 가질 수 있는지 고려해야 합니다.

### 2. 이상치 처리 방법

* **제거 (Trimming)**: 이상치를 포함한 관측치(행)를 완전히 제거. (데이터 손실 발생)
* **대치 (Substitution / Capping and Flooring)**:
    * 이상치를 결측값으로 간주하여 결측값 처리 방법을 적용.
    * 극단적인 값을 **상한값/하한값**으로 대체하는 방법 (예: $\text{IQR}$의 3배를 초과하는 값을 상한값으로 대체).
* **변수화 (Feature Engineering)**: 이상치가 중요한 의미를 가질 경우, 이를 새로운 **설명 변수(더미 변수 등)**로 변환하여 모델에 포함.

## 11.3. 변수 구간화

🎯**학습 목표: 데이터 변환과 가공 기법을 학습하고 활용할 수 있다.**

**연속형/이산형 변수**를 **범주형 변수(Categorical variable)**로 변환하여 분석 성능을 높이거나 해석의 편의성을 개선하는 기법입니다.

### 📏 1. 변수 구간화 기법

* **동일 폭 구간화 (Equal Interval)**: 최솟값과 최댓값 사이를 **일정한 간격(폭)**으로 나누어 범주 생성.
* **동일 빈도 구간화 (Equal Frequency)**: 각 구간에 속하는 **관측치의 수(빈도)**가 유사하도록 구간을 나누어 범주 생성.
* **평활화 (Smoothing)**: 구간화된 값들을 해당 구간의 평균, 중앙값 등으로 대체하여 이산 값으로 변환.

### 2. 구간화 평가

* **WOE (Weight of Evidence) & IV (Information Value)**: 구간화가 종속 변수(타깃)에 대한 예측력을 얼마나 높였는지 측정하는 지표.
* **판단 기준**: 일반적으로 **IV 값이 0.3 이상**이면 해당 변수의 예측력이 우수하다고 판단.


## 11.4. 데이터 표준화와 정규화 스케일링

🎯**학습 목표: 데이터 변환과 가공 기법을 학습하고 활용할 수 있다.**

서로 단위가 다르거나 편차가 심한 독립 변수들의 **스케일을 조정**하여 모델 학습 시 특정 변수가 과도하게 영향을 미치는 것을 방지하고 성능을 향상시키는 필수 과정입니다.

| 구분 | 표준화 (Standardization) | 정규화 (Normalization) | RobustScaler (강건한 스케일링) |
| :--- | :--- | :--- | :--- |
| **개념** | 평균을 기준으로 얼마나 떨어져 있는지 (Z-score) | 0부터 1까지의 범위로 조정 | 이상치에 민감한 단점을 보완 |
| **변환 공식** | $z = (x - \mu) / \sigma$ | $\text{Scaled}_x = (x - \text{min}) / (\text{max} - \text{min})$ | 중앙값($Q2$)과 $\text{IQR}$을 사용 |
| **결과 특징** | 평균 0, 표준편차 1. 범위가 고정되지 않아 극단값 확장 가능. | 최솟값 0, 최댓값 1. 데이터가 전체 범위 내에서 상대적 위치 파악 용이. | 중앙값을 사용하므로 **이상치의 영향**을 거의 받지 않음. |

### 💡 스케일링의 중요성

1.  **거리를 활용하는 모델**: **k-Nearest Neighbor**, **Support Vector Machine (SVM)**, 군집 분석(Clustering) 등 거리를 기반으로 하는 모델에서는 필수적입니다.
2.  **신경망 모델**: 학습 효율과 분류 성능을 높이기 위해 표준화 또는 정규화가 요구됩니다.
3.  **선택 가이드**:
    * **이상치 영향 최소화**가 중요할 경우 $\rightarrow$ **RobustScaler**
    * 일반적인 경우 $\rightarrow$ 표준화($Z$-score)가 정규화보다 대체로 성능이 우수하다고 알려져 있습니다.

<br>
<br>

---

# 2️⃣ 확인 과제

> **교재에 있는 실습 파트를 직접 따라 해보세요. 실습을 완료한 뒤, 결과화면(캡처 또는 코드 결과)을 첨부하여 인증해 주세요.**
>
> **단순 이론 암기보다, 직접 손으로 따라해보면서 실습해 보는 것이 가장 확실한 학습 방법입니다.**
>
> > **인증 예시 : 통계 프로그램 결과, 시각화 이미지 캡처 등**

## 결측값 시각화
![alt text](<Images_5/결측값 시각화(1).png>)
![alt text](<Images_5/결측값 시각화(2).png>)

## 박스플롯
![alt text](<Images_5/BMI 박스플롯.png>)

## 박스플롯 이상치 제거
![alt text](<Images_5/박스플롯 이상치 제거.png>)

## 분포 시각화
![alt text](<Images_5/분포 시각화.png>)

## bin 분포 시각화
![alt text](<Images_5/bin_분포 시각화.png>)

## bin3 분포 시각화
![alt text](<Images_5/bin3 칼럼 분포 시각화.png>)

## 표준화 스케일링
![alt text](<Images_5/표준화 스케일링.png>)

## 정규화 스케일링
![alt text](<Images_5/정규화 스케일링.png>)

## RobustScaler 스케일링
![alt text](<Images_5/RobustScaler 스케일링.png>)

~~~
인증 이미지가 없으면 과제 수행으로 인정되지 않습니다.
~~~



### 🎉 수고하셨습니다.