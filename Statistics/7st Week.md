# 통계학 7주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_7th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

7주차는 `2부-데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다


## Statistics_7th_TIL

### 2부. 데이터 분석 준비하기

### 11. 데이터 전처리와 파생변수 생성

<!-- 11.5 모델 성능 향상을 위한 파 변수 생성부터 11장 끝까지 진행해주시면 됩니다.-->

## Study ScheduleStudy Schedule

| 주차  | 공부 범위     | 완료 여부 |
| ----- | ------------- | --------- |
| 1주차 | 1부 p.2~46    | ✅         |
| 2주차 | 1부 p.47~81   | ✅         |
| 3주차 | 2부 p.82~120  | ✅         |
| 4주차 | 2부 p.121~167 | ✅         |
| 5주차 | 2부 p.168~202 | ✅         |
| 6주차 | 2부 p.203~250 | ✅         |
| 7주차 | 2부 p.251~299 | ✅         |

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리 

## 11.데이터 전처리와 파생변수 생성

```
✅ 학습 목표 :
* 결측값과 이상치를 식별하고 적절한 방법으로 처리할 수 있다.
* 데이터 변환과 가공 기법을 학습하고 활용할 수 있다.
* 모델 성능 향상을 위한 파생 변수를 생성하고 활용할 수 있다.
```

### 11.5. 모델 성능 향상을 위한 파생 변수 생성

파생 변수(Derived variable)는 **원래의 변수들을 조합하거나 함수를 적용**하여 새롭게 만들어낸 변수입니다. 그 목적은 **데이터의 특성을 활용하여 분석 효율을 높이고 모델 성능을 향상**시키는 데 있습니다.

| 주요 학습 내용 | 세부 설명 |
| :--- | :--- |
| **파생 변수의 정의와 활용** | 간단한 변수 조합(예: X1, X2 두 변수의 평균값) 외에도, 데이터 구간화, 표준화, 정규화 등도 일종의 파생 변수로 볼 수 있습니다. 로그, 제곱근, 지수 함수 등을 취해 **변동성을 완화**시키거나 분포를 분석에 적합하도록 변경할 수 있으며, **과거 시점 대비 변화 정도**를 반영하여 생성할 수 있습니다. |
| **비즈니스 도메인 지식의 중요성** | 단순한 변수 가공을 넘어, **해당 비즈니스 도메인에 대한 충분한 이해**를 바탕으로 숨겨진 현상(예: 특정 나이대에서 판매량이 크게 변하는 현상)을 반영하는 파생 변수를 만들어 분석 모델의 성능을 향상시킬 수 있습니다. |
| **다중공선성 문제 유의** | 파생 변수는 기존 변수를 활용하여 만들기 때문에 **다중공선성(Multicollinearity)** 문제가 발생할 가능성이 높습니다. 따라서 상관 분석을 통해 상관성을 확인하고, 경우에 따라 기존 변수를 제외하거나 주성분 분석(PCA) 등을 사용하여 변수 조합의 주요 속성만 추출할지 결정해야 합니다. |

### 11.6. 슬라이딩 윈도우 데이터 가공

슬라이딩 윈도우(Sliding window) 기법은 예측 모델링에서 **데이터 양을 늘리고 학습 데이터의 최근성**을 확보하여 모델 성능을 높이는 데 유용합니다.

| 주요 학습 내용 | 세부 설명 |
| :--- | :--- |
| **슬라이딩 윈도우의 개념** | 현재 시점으로부터 $\pm M$ 기간의 데이터를 일정 시간마다 전송하는 방식입니다. 데이터를 **겹치게 쪼개어 전송**함으로써 **전체 데이터의 증거(evidence)**를 증가시키는 것이 핵심입니다. |
| **예측 모델에서의 유용성** | 학습 시점과 예측 시점의 차이가 클 때(예: 6개월 학습 후 현재 시점 예측), 이 기법을 통해 **많은 분석 데이터를 확보**하고 학습 데이터가 최근성을 가지도록 만들 수 있어 예측 모델에 유용합니다. |
| **관측치 복제 효과** | 동일한 고객이라도 1월부터 5월까지의 활동 후 6월 구매와 2월부터 6월까지의 활동 후 7월 구매는 서로 다른 관측치로 간주될 수 있습니다. 이 방법을 통해 고객의 활동 정보를 **시간의 흐름에 따라 복제**하여 데이터 테이블의 관측치 수를 늘릴 수 있습니다. |

### 11.7. 범주형 변수의 가변수 처리

가변수(Dummy variable) 처리는 범주형 변수(예: 성별, 혈액형)를 0과 1의 값을 가지는 **이진 변수(Binary variable)**로 변환하는 기법입니다.

| 주요 학습 내용 | 세부 설명 |
| :--- | :--- |
| **가변수 처리의 목적** | **선형 회귀분석이나 로지스틱 회귀분석**과 같은 회귀분석 모델은 기본적으로 **연속형 변수**만 사용할 수 있습니다. 범주형 변수를 가변수(더미 변수)로 변환함으로써 이러한 분석 방법론에 적용할 수 있게 됩니다. |
| **가변수 생성 원칙 (N-1)** | 범주형 변수를 가변수로 만들 때, **범주의 수보다 1개 적게** 가변수를 생성해야 합니다. 예를 들어 4개의 범주가 있다면 3개의 가변수를 만듭니다. |
| **다중공선성 방지** | 범주 수만큼 가변수를 생성하면 독립 변수 간에 상호 영향을 주어 **다중공선성(Multicollinearity)** 문제가 발생합니다. N-1개만 생성하여 **독립 변수 간의 독립성(Independency)**을 유지해야 합니다. |
| **기준 변수 (Baseline) 해석** | 제거된 하나의 범주(기준 변수)의 종속 변수에 대한 영향력은 0으로 설정됩니다. 나머지 가변수들의 계수는 이 **기준 변수 대비** 다른 범주들이 종속 변수에 미치는 영향력을 산출하게 됩니다. |
| **결측값 처리 옵션** | 가변수 처리 시 `dummy_na=True` 옵션을 적용하면 결측값을 별도의 범주로 처리하는 가변수를 생성하여 결측값의 의미를 분석에 활용할 수 있습니다. |

### 11.8. 클래스 불균형 문제 해결을 위한 언더샘플링과 오버샘플링

클래스 불균형(Class disparity) 문제는 이진 분류 모델에서 클래스 비중이 크게 차이 날 때(예: 90% 대 10%), 모델이 **비중이 적은 클래스의 특성을 제대로 학습하지 못해 예측 정확도가 떨어지는** 현상을 유발합니다.

| 주요 학습 내용 | 세부 설명 |
| :--- | :--- |
| **해결 방법** | 1) **가중치 균형(Weight balancing)**: 모델 자체에 가중치나 손실 가중치를 부여하여 중요한 클래스를 강조합니다. 2) **샘플링 기법**: 데이터의 구성을 조정합니다. |
| **언더샘플링 (Under-sampling)** | **비중이 큰 클래스의 관측치**를 줄여 비중이 작은 클래스의 수와 동일하도록 맞추는 방법입니다. (예: 랜덤 언더샘플링, EasyEnsemble, CNN) |
| **오버샘플링 (Over-sampling)** | **비중이 작은 클래스의 관측치**를 늘려 비중이 큰 클래스의 수와 동일하도록 증가시키는 방법입니다. (예: 랜덤 오버샘플링, **SMOTE**, **ADASYN**) |
| **SMOTE 및 ADASYN** | **SMOTE (Synthetic Minority Over-Sampling Technique)**는 K-Nearest Neighbors를 사용하여 이웃 관측치 사이의 값을 보간하여 **가상적인 새로운 관측치(Synthetic samples)**를 생성합니다. **ADASYN**은 SMOTE를 발전시켜 불균형 정도에 따라 오버샘플링 할 양을 체계적으로 조절할 수 있습니다. |
| **샘플링 적용 시 유의점** | 언더샘플링이나 오버샘플링은 모델 성능 향상을 위해 **반드시 학습 데이터셋(Train set)에만 적용**해야 합니다. 테스트셋에는 순수한 데이터를 사용하여 모델의 실제 예측 성능을 검증해야 합니다. |

### 11.9. 데이터 거리 측정 방법

데이터 간의 **거리(Distance)** 또는 **유사도(Similarity)** 측정은 분류 모델, 군집 모델, 추천 시스템 등 다양한 분석에서 필수적으로 사용됩니다. 거리 측정 전에는 **표준화나 정규화**를 거쳐야 합니다.

| 측정 방법 | 특징 및 정의 |
| :--- | :--- |
| **유클리드 거리 (Euclidean distance)** | 가장 대표적인 알고리즘으로, 피타고라스 정리를 활용한 **직선 거리**를 측정합니다 (L2 Norm). 거리가 0에 가까울수록 유사도가 높습니다. |
| **맨해튼 거리 (Manhattan distance)** | 뉴욕 맨해튼의 도로처럼 X축과 Y축 거리를 합산한 최단 거리를 측정합니다 (L1 Norm). |
| **민코프스키 거리 (Minkowski distance)** | p-norm 값을 설정하여 거리 측정 기준을 조정하는 일반화된 방법입니다. p=1은 맨해튼 거리, p=2는 유클리드 거리와 같습니다. |
| **체비쇼프 거리 (Chebyshev distance)** | 두 관측치 간의 **최대 거리(Maximum distance)**를 구하는 데 사용됩니다 (L Max Norm). |
| **마할라노비스 거리 (Mahalanobis distance)** | 유클리드 거리에 **공분산(Covariance)**을 고려하여 변수 간의 상관성을 함께 반영하여 측정합니다. |
| **코사인 유사도/거리 (Cosine similarity/distance)** | 두 벡터의 **크기(magnitude)가 아닌 방향(각도)**만을 이용해 유사도를 측정합니다. 문서 유사도 측정 등 크기가 중요하지 않은 경우에 적합합니다. **코사인 거리**는 1에서 코사인 유사도를 뺀 값입니다. |

<br>
<br>

---

# 2️⃣ 확인 과제

> **교재에 있는 실습 파트를 직접 따라 해보세요. 실습을 완료한 뒤, 결과화면(캡처 또는 코드 결과)을 첨부하여 인증해 주세요.**
>
> **단순 이론 암기보다, 직접 손으로 따라해보면서 실습해 보는 것이 가장 확실한 학습 방법입니다.**
>
> > **인증 예시 : 통계 프로그램 결과, 시각화 이미지 캡처 등**

<!-- 이 주석을 지우고 “실습 결과 화면(캡처)을 이곳에 첨부해주세요.-->

~~~
인증 이미지가 없으면 과제 수행으로 인정되지 않습니다.
~~~



---

# 3️⃣ 실습 과제 (마지막 과제)

>  **🧚Q. 마지막 과제는 다음과 같습니다. 『데이터 분석가가 반드시 알아야 할 모든 것』 2부를 마무리하는 주차로,그동안 배운 데이터 전처리 및 파생변수 생성 내용을 실제 데이터에 적용해 보는 실습형 과제입니다. 단순히 함수를 실행하는 데서 그치지 않고, "왜 이 전처리 방법을 선택했는가" 와 "데이터가 말해주는 인사이트는 무엇인가'를 중심으로 EDA(탐색적 데이터 분석)를 함께 수행해주세요.**
>
> (정규과제 업로드 시트에 과제를 수행한 Git 링크와 코랩도 같이 올려주세요) 

<!-- 4주차 과제부터 실습하면서 배운 파이썬 문법을 적용하면서 실습을 진행해주세요 -->

~~~
과제 가이드라인

1. 실습 데이터셋 불러오기
Kaggle : Students Performance in Exams
- 출처: https://www.kaggle.com/datasets/spscientist/students-performance-in-exams
- 설명:
미국 고등학생 1000명의 성적과 배경 요인(성별, 인종, 부모 학력, 점심 여부, 시험 준비 과정 등)을 담은 데이터입니다.
math score, reading score, writing score 3가지 점수를 기준으로
학업 성취에 영향을 미치는 요인을 분석해볼 수 있습니다.

2. 데이터 전처리 진행하기
교재에서 배웠던 개념들을 적용해면서 전처리를 진행해봅시다. 
- 결측값 처리, 이상치 처리, 스케일링 등 
- (Optional) 범주형 변수 인코딩, 파생 변수 생성

3. EDA (탐색적 데이터 분석)
전처리된 데이터를 바탕으로 자유롭게 시각화 및 요약 분석을 수행하세요. 
- 점수 간 상관관계 분석
- 그룹 별 비교
- 여러 과정에 따른 성적 분포 비교
- 변수 간 관계 시각화 

4. 주석이나 코드 설명에서 들어가야 할 부분
- 교재에 있는 어떤 통계 개념을 적용했는지
- 각 개념이 데이터 분석에서 어떻게 활용되었는지를 스스로 설명해보세요.
- 단순한 코드 작성보다, 통계 개념 -> 코드 적용 -> 해석 -> 배운 점의 흐름을 명확히 드러내는 것이 핵심 기준입니다. 
~~~



<!-- 이것으로 통계학 정규과제가 마무리 되었습니다.  자료실에서 보면 아시겠지만, 이번 통계학 정규과제는 2부까지만 진행을 하였습니다. 3부부터는 모델에 대한 개념이 등장하기 때문에, 수학적 통계학을 배우고 분석의 기초를 다지는 부분에 여러분이 더 집중할 수 있도록 구성했습니다. 또한 전체 분량이 길기 때문에 학습 부담을 줄이기 위한 결정입니다. 따라서 이번 주차를 끝으로 정규 과제는 마무리되지만, 머신러닝 모델에 대해 더 깊이 공부하고 싶은 분들은 3부를 개인적으로 학습해보는 것을 추천드립니다. 그동안 과제를 열심히 하느라 고생하셨습니다. -->

### 🎉 수고하셨습니다.